{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query the Nemotron Parse API\n",
    "\n",
    "This notebook demonstrates how to interact with the NVIDIA Nemotron Parse API using Python. \n",
    "It covers launching the NIM container, sending a request with an image, and visualizing the detected bounding boxes.\n",
    "\n",
    "Reference: [NVIDIA Docs](https://docs.nvidia.com/nim/vision-language-models/latest/examples/nemotron-parse/api.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Launch NIM\n",
    "\n",
    "Before running the Python code, you need to launch the Nemotron Parse NIM container. \n",
    "Run the following command in your terminal (ensure you have `ngc` configured and Docker installed):\n",
    "\n",
    "```bash\n",
    "# Choose a container name for bookkeeping \n",
    "export CONTAINER_NAME=\"nvidia-nemotron-parse\" \n",
    "# The container name from the previous ngc registry image list command \n",
    "Repository=\"nemotron-parse\"\n",
    "Latest_Tag=\"1.5.0\"\n",
    "\n",
    "# Choose a VLM NIM Image from NGC \n",
    "export IMG_NAME=\"nvcr.io/nim/nvidia/${Repository}:${Latest_Tag}\" \n",
    "\n",
    "# Choose a path on your system to cache the downloaded models \n",
    "export LOCAL_NIM_CACHE=~/.cache/nim \n",
    "mkdir -p \"$LOCAL_NIM_CACHE\" \n",
    "\n",
    "# Start the VLM NIM \n",
    "docker run -it --rm --name=$CONTAINER_NAME \\\n",
    "  --runtime=nvidia \\\n",
    "  --gpus all \\\n",
    "  --shm-size=16GB \\\n",
    "  -e NGC_API_KEY=$NGC_API_KEY \\\n",
    "  -v \"$LOCAL_NIM_CACHE:/opt/nim/.cache\" \\\n",
    "  -u $(id -u) \\\n",
    "  -p 8000:8000 \\\n",
    "  $IMG_NAME\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openai pillow requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Query the API\n",
    "\n",
    "We will send a request to the local API endpoint. We'll use an example image URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "from openai import OpenAI\n",
    "\n",
    "# Initialize client\n",
    "client = OpenAI(\n",
    "    base_url=\"http://0.0.0.0:8000/v1\",\n",
    "    # For local deployment, an API key is not needed but must be non-empty\n",
    "    api_key=\"dummy-key\"\n",
    ")\n",
    "\n",
    "# Example Image URL from docs\n",
    "image_url = \"https://raw.githubusercontent.com/vis-nlp/ChartQA/main/ChartQA%20Dataset/val/png/5090.png\"\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"nvidia/nemotron-parse\",\n",
    "    # See Tool types section for more information.\n",
    "    tools=[{\"type\": \"function\", \"function\": {\"name\": \"markdown_bbox\"}}],\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": image_url\n",
    "                    },\n",
    "                },\n",
    "            ]\n",
    "        }\n",
    "    ],\n",
    "    temperature=0.0,\n",
    ")\n",
    "\n",
    "tool_call = completion.choices[0].message.tool_calls[0]\n",
    "results_of_detection = json.loads(tool_call.function.arguments)[0]\n",
    "\n",
    "print(\"Detection Results:\")\n",
    "print(json.dumps(results_of_detection, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualize Results\n",
    "\n",
    "We will now visualize the bounding boxes on the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "# Download the image for visualization\n",
    "response = requests.get(image_url)\n",
    "image = Image.open(BytesIO(response.content))\n",
    "image.save(\"example.png\") # Save locally as the script expects, or use object directly\n",
    "\n",
    "# --- Start of NVIDIA Visualization Script ---\n",
    "\n",
    "detections = results_of_detection\n",
    "\n",
    "# Reload image to follow script exactly, or use 'image' object directly\n",
    "# image = Image.open(\"example.png\") \n",
    "draw = ImageDraw.Draw(image)\n",
    "width, height = image.size\n",
    "\n",
    "colors = [\"red\", \"green\", \"blue\", \"yellow\", \"magenta\", \"cyan\", \"orange\", \"purple\"]\n",
    "\n",
    "try:\n",
    "    font = ImageFont.truetype(\"arial.ttf\", 16)\n",
    "except IOError:\n",
    "    font = ImageFont.load_default()\n",
    "\n",
    "for i, det in enumerate(detections):\n",
    "    bbox = det[\"bbox\"]\n",
    "    # Convert normalized coordinates to pixel values.\n",
    "    left = bbox[\"xmin\"] * width\n",
    "    top = bbox[\"ymin\"] * height\n",
    "    right = bbox[\"xmax\"] * width\n",
    "    bottom = bbox[\"ymax\"] * height\n",
    "\n",
    "    # Choose a color for the box.\n",
    "    color = colors[i % len(colors)]\n",
    "\n",
    "    # Draw the bounding box with a 3-pixel thick outline.\n",
    "    draw.rectangle([left, top, right, bottom], outline=color, width=3)\n",
    "\n",
    "    # Use the 'type' key as the label title.\n",
    "    label = det.get(\"type\", \"\")\n",
    "\n",
    "    # Instead of measuring text size, use a fixed-size background.\n",
    "    fixed_label_width = 80  # Fixed width for the label background\n",
    "    fixed_label_height = 20  # Fixed height for the label background\n",
    "\n",
    "    # Draw a filled rectangle above the bounding box for the label background.\n",
    "    draw.rectangle([left, top - fixed_label_height, left + fixed_label_width, top], fill=color)\n",
    "\n",
    "    # Draw the label text (with a small padding).\n",
    "    draw.text((left + 3, top - fixed_label_height + 3), label, fill=\"black\", font=font)\n",
    "\n",
    "image.save(\"example_result.png\")\n",
    "print(\"Saved visualization to example_result.png\")\n",
    "\n",
    "# Display the image in notebook\n",
    "image\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}