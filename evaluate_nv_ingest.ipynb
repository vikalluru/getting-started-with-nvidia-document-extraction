{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Nemotron Parse and NeMoRetriever OCR Evaluation with NV Ingest\n",
    "\n",
    "**Important Notes**: \n",
    "1. In order to run this notebook, you need create a NGC account and get an API Key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "NVIDIA-Ingest is a scalable, performance-oriented document content and metadata extraction microservice. For more information, see [What is NVIDIA Ingest?](https://docs.nvidia.com/nemo/retriever/extraction/overview/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Architecture\n",
    "\n",
    "NV Ingest architecture\n",
    "\n",
    "![arch](./nv_ingest_image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Getting started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clone the repository and log into Docker\n",
    "\n",
    "In order to spin up this blueprint, you will need an NGC api key. After you get your API key, paste it in the `.env` file and run the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HEAD is now at b63eecea docs: Fix helm link in release notes (#1037)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created .env file\n",
      "Login Succeeded\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "# Paste your NGC API key in .env file before running the cell below\n",
    "\n",
    "[ -d \"nv-ingest\" ] || git clone https://github.com/nvidia/nv-ingest\n",
    "\n",
    "cd nv-ingest\n",
    "git checkout 25.9.0\n",
    "\n",
    "export NGC_API_KEY=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\n",
    "\n",
    "cat > .env << 'EOF'\n",
    "NGC_API_KEY=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\n",
    "DATASET_ROOT=./data\n",
    "NV_INGEST_ROOT=./nv-ingest\n",
    "\n",
    "# NeMo Retriever OCR Configuration (high-performance OCR)\n",
    "# Reference: https://build.nvidia.com/nvidia/nemoretriever-ocr-v1/deploy\n",
    "    \"OCR_IMAGE=nvcr.io/nim/nvidia/nemoretriever-ocr-v1\\n\",\n",
    "    \"OCR_TAG=1.2.1\\n\",\n",
    "OCR_MODEL_NAME=scene_text_ensemble\n",
    "EOF\n",
    "echo \"Created .env file\"\n",
    "\n",
    "echo \"${NGC_API_KEY}\" | docker login nvcr.io -u '$oauthtoken' --password-stdin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spin up the Blueprint\n",
    "\n",
    "Choose **ONE** of the following two options to spin up NV-Ingest:\n",
    "\n",
    "- **Option A**: Standard NIM Pipeline (uses YOLOX + Deplot + NeMo Retriever OCR)\n",
    "- **Option B**: NemoRetriever Parse Pipeline (uses state-of-the-art NemoRetriever Parse model)\n",
    "\n",
    "---\n",
    "\n",
    "## Option A: Standard NIM Pipeline\n",
    "\n",
    "This option uses the multi-NIM approach with specialized models for each task:\n",
    "- **YOLOX**: Table structure detection\n",
    "- **Deplot**: Chart extraction  \n",
    "- **NeMo Retriever OCR**: High-performance text extraction\n",
    "\n",
    "**NOTE**: This step can take about 10 minutes. The following steps are how we suggest running and monitoring your progress.\n",
    "\n",
    "1. Open up a new terminal window and run the following:\n",
    "\n",
    "```bash\n",
    "cd nv-ingest\n",
    "docker compose --profile retrieval --profile table-structure up\n",
    "```\n",
    "\n",
    "This will run each service and output persistent logs.\n",
    "\n",
    "2. In a second terminal window, run:\n",
    "\n",
    "```bash\n",
    "cd nv-ingest\n",
    "docker compose logs -f nv-ingest-ms-runtime\n",
    "```\n",
    "\n",
    "This will show you persistent logs for the main `nv-ingest` service.\n",
    "\n",
    "**To stop this deployment later:**\n",
    "```bash\n",
    "cd nv-ingest\n",
    "docker compose --profile retrieval --profile table-structure down\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Option B: NemoRetriever Parse Pipeline\n",
    "\n",
    "This option uses the **NemoRetriever Parse** model for state-of-the-art PDF extraction:\n",
    "- Single model handles text, tables, and document structure\n",
    "- Generally better accuracy for complex documents\n",
    "- Higher GPU memory requirements\n",
    "\n",
    "**Reference**: [NemoRetriever Parse Documentation](https://docs.nvidia.com/nemo/retriever/latest/extraction/nemoretriever-parse/)\n",
    "\n",
    "**NOTE**: This step can take about 10-15 minutes on first startup as NIM containers pull and load models.\n",
    "\n",
    "1. Open up a new terminal window and run the following:\n",
    "\n",
    "```bash\n",
    "cd nv-ingest\n",
    "docker compose --profile retrieval --profile table-structure --profile nemoretriever-parse up\n",
    "```\n",
    "\n",
    "This will run each service including NemoRetriever Parse and output persistent logs.\n",
    "\n",
    "2. In a second terminal window, run:\n",
    "\n",
    "```bash\n",
    "cd nv-ingest\n",
    "docker compose logs -f nv-ingest-ms-runtime\n",
    "```\n",
    "\n",
    "This will show you persistent logs for the main `nv-ingest` service.\n",
    "\n",
    "**To stop this deployment later:**\n",
    "```bash\n",
    "cd nv-ingest\n",
    "docker compose --profile retrieval --profile table-structure --profile nemoretriever-parse down\n",
    "```\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking for completion\n",
    "Things should be spun up properly if the first part of your `nv-ingest-ms-runtime` logs show something similar to \n",
    "\n",
    "```bash\n",
    "nv-ingest-ms-runtime-1  | INFO:     Uvicorn running on http://0.0.0.0:7670 (Press CTRL+C to quit)\n",
    "nv-ingest-ms-runtime-1  | INFO:     Started parent process [20]\n",
    "nv-ingest-ms-runtime-1  | INFO:     Started server process [40]\n",
    "```\n",
    "\n",
    "and the final lines look similar to \n",
    "\n",
    "```bash\n",
    "nv-ingest-ms-runtime-1  | 2024-10-16 02:36:11,162 - DEBUG - parent_receive started child_thread\n",
    "nv-ingest-ms-runtime-1  | 2024-10-16 02:36:11,162 - DEBUG - parent_receive started child_thread\n",
    "nv-ingest-ms-runtime-1  | 2024-10-16 02:36:11,163 - DEBUG - parent_receive started child_thread\n",
    "```\n",
    "\n",
    "After everything is up and running, we can run `docker ps` and `nvidia-smi` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONTAINER ID   IMAGE                                                           COMMAND                  CREATED         STATUS                   PORTS                                                                                                                                                                                                                                                                                                                   NAMES\n",
      "54e72e9297eb   zilliz/attu:v2.3.5                                              \"docker-entrypoint.s\u2026\"   5 minutes ago   Up 5 minutes             0.0.0.0:3001->3000/tcp, [::]:3001->3000/tcp                                                                                                                                                                                                                                                                             milvus-attu\n",
      "28563a922382   milvusdb/milvus:v2.5.3-gpu                                      \"/tini -- milvus run\u2026\"   5 minutes ago   Up 5 minutes (healthy)   0.0.0.0:9091->9091/tcp, [::]:9091->9091/tcp, 0.0.0.0:19530->19530/tcp, [::]:19530->19530/tcp                                                                                                                                                                                                                            milvus-standalone\n",
      "c911e5eda62e   otel/opentelemetry-collector-contrib:0.91.0                     \"/otelcol-contrib --\u2026\"   5 minutes ago   Up 5 minutes             0.0.0.0:4317-4318->4317-4318/tcp, [::]:4317-4318->4317-4318/tcp, 0.0.0.0:8889->8889/tcp, [::]:8889->8889/tcp, 0.0.0.0:9988->9988/tcp, [::]:9988->9988/tcp, 0.0.0.0:13133->13133/tcp, [::]:13133->13133/tcp, 55678/tcp, 0.0.0.0:32768->9411/tcp, [::]:32768->9411/tcp, 0.0.0.0:55680->55679/tcp, [::]:55680->55679/tcp   nv-ingest-otel-collector-1\n",
      "ceee6442a625   nvcr.io/nim/nvidia/nemoretriever-graphic-elements-v1:1.5.0      \"/opt/nvidia/nvidia_\u2026\"   7 minutes ago   Up 5 minutes             0.0.0.0:8003->8000/tcp, [::]:8003->8000/tcp, 0.0.0.0:8004->8001/tcp, [::]:8004->8001/tcp, 0.0.0.0:8005->8002/tcp, [::]:8005->8002/tcp                                                                                                                                                                                   nv-ingest-graphic-elements-1\n",
      "20e0b7f63d93   nvcr.io/nim/nvidia/nemoretriever-page-elements-v2:1.5.0         \"/opt/nvidia/nvidia_\u2026\"   7 minutes ago   Up 5 minutes             0.0.0.0:8000-8002->8000-8002/tcp, [::]:8000-8002->8000-8002/tcp                                                                                                                                                                                                                                                         nv-ingest-page-elements-1\n",
      "c25a0e2a26ac   nvcr.io/nvidia/nemo-microservices/nemoretriever-ocr-v1:latest   \"/opt/nvidia/nvidia_\u2026\"   7 minutes ago   Up 5 minutes             0.0.0.0:8009->8000/tcp, [::]:8009->8000/tcp, 0.0.0.0:8010->8001/tcp, [::]:8010->8001/tcp, 0.0.0.0:8011->8002/tcp, [::]:8011->8002/tcp                                                                                                                                                                                   nv-ingest-ocr-1\n",
      "276b0d063a8b   nvcr.io/nim/nvidia/llama-3.2-nv-embedqa-1b-v2:1.10.0            \"/opt/nvidia/nvidia_\u2026\"   7 minutes ago   Up 5 minutes             0.0.0.0:8012->8000/tcp, [::]:8012->8000/tcp, 0.0.0.0:8013->8001/tcp, [::]:8013->8001/tcp, 0.0.0.0:8014->8002/tcp, [::]:8014->8002/tcp                                                                                                                                                                                   nv-ingest-embedding-1\n",
      "62d662da4381   minio/minio:RELEASE.2023-03-20T20-16-18Z                        \"/usr/bin/docker-ent\u2026\"   7 minutes ago   Up 5 minutes (healthy)   0.0.0.0:9000-9001->9000-9001/tcp, [::]:9000-9001->9000-9001/tcp                                                                                                                                                                                                                                                         minio\n",
      "e92cbfc6a51e   nvcr.io/nim/nvidia/nemoretriever-table-structure-v1:1.5.0       \"/opt/nvidia/nvidia_\u2026\"   7 minutes ago   Up 5 minutes             0.0.0.0:8006->8000/tcp, [::]:8006->8000/tcp, 0.0.0.0:8007->8001/tcp, [::]:8007->8001/tcp, 0.0.0.0:8008->8002/tcp, [::]:8008->8002/tcp                                                                                                                                                                                   nv-ingest-table-structure-1\n",
      "627a70957e23   prom/prometheus:latest                                          \"/bin/prometheus --w\u2026\"   7 minutes ago   Up 5 minutes             0.0.0.0:9090->9090/tcp, [::]:9090->9090/tcp                                                                                                                                                                                                                                                                             nv-ingest-prometheus-1\n",
      "52fbbac4fe45   openzipkin/zipkin                                               \"start-zipkin\"           7 minutes ago   Up 5 minutes (healthy)   9410/tcp, 0.0.0.0:9411->9411/tcp, [::]:9411->9411/tcp                                                                                                                                                                                                                                                                   nv-ingest-zipkin-1\n",
      "ccdded27b0ee   nvcr.io/nvidia/nemo-microservices/nv-ingest:25.9.0              \"/opt/conda/envs/nv_\u2026\"   7 minutes ago   Up 5 minutes (healthy)   0.0.0.0:7670->7670/tcp, [::]:7670->7670/tcp, 0.0.0.0:8265->8265/tcp, [::]:8265->8265/tcp                                                                                                                                                                                                                                nv-ingest-nv-ingest-ms-runtime-1\n",
      "004f6e8dfd68   redis/redis-stack                                               \"/entrypoint.sh\"         7 minutes ago   Up 5 minutes             0.0.0.0:6379->6379/tcp, [::]:6379->6379/tcp, 8001/tcp                                                                                                                                                                                                                                                                   nv-ingest-redis-1\n",
      "3a290df5fa2c   grafana/grafana                                                 \"/run.sh\"                7 minutes ago   Up 5 minutes             0.0.0.0:3000->3000/tcp, [::]:3000->3000/tcp                                                                                                                                                                                                                                                                             grafana-service\n",
      "ac0f869785a9   quay.io/coreos/etcd:v3.5.5                                      \"etcd -advertise-cli\u2026\"   7 minutes ago   Up 5 minutes (healthy)   2379-2380/tcp                                                                                                                                                                                                                                                                                                           milvus-etcd\n"
     ]
    }
   ],
   "source": [
    "!docker ps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you run `docker ps` you should see output similar to the following that lists your container images and the status of each. If any status includes `starting`, wait for the container to start before you proceed.\n",
    "\n",
    "```text\n",
    "CONTAINER ID   IMAGE                                        COMMAND                 CREATED            STATUS                      PORTS          \n",
    "9869e432cc04   zilliz/attu:v2.3.5                           \"docker-entrypoint.s\u2026\"  About an hour ago  Up About an hour            0.0.0.0:3001...\n",
    "e02baf85ccc5   otel/opentelemetry-collector-contrib:0.91.0  \"/otelcol-contrib --\u2026\"  About an hour ago  Up About an hour            0.0.0.0:4317...\n",
    "4c3be36de11b   milvusdb/milvus:v2.5.3-gpu                   \"/tini -- milvus run\u2026\"  About an hour ago  Up About an hour (healthy)  0.0.0.0:9091...\n",
    "...\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment 'Python' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interacting with NV Ingest\n",
    "\n",
    "There are 2 ways to interact with `nv-ingest`, a python client and a CLI. Lets use the Python client first "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing the Python Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31merror\u001b[0m: \u001b[1mexternally-managed-environment\u001b[0m\n",
      "\n",
      "\u001b[31m\u00d7\u001b[0m This environment is externally managed\n",
      "\u001b[31m\u2570\u2500>\u001b[0m To install Python packages system-wide, try apt install\n",
      "\u001b[31m   \u001b[0m python3-xyz, where xyz is the package you are trying to\n",
      "\u001b[31m   \u001b[0m install.\n",
      "\u001b[31m   \u001b[0m \n",
      "\u001b[31m   \u001b[0m If you wish to install a non-Debian-packaged Python package,\n",
      "\u001b[31m   \u001b[0m create a virtual environment using python3 -m venv path/to/venv.\n",
      "\u001b[31m   \u001b[0m Then use path/to/venv/bin/python and path/to/venv/bin/pip. Make\n",
      "\u001b[31m   \u001b[0m sure you have python3-full installed.\n",
      "\u001b[31m   \u001b[0m \n",
      "\u001b[31m   \u001b[0m If you wish to install a non-Debian packaged Python application,\n",
      "\u001b[31m   \u001b[0m it may be easiest to use pipx install xyz, which will manage a\n",
      "\u001b[31m   \u001b[0m virtual environment for you. Make sure you have pipx installed.\n",
      "\u001b[31m   \u001b[0m \n",
      "\u001b[31m   \u001b[0m See /usr/share/doc/python3.12/README.venv for more information.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: If you believe this is a mistake, please contact your Python installation or OS distribution provider. You can override this, at the risk of breaking your Python installation or OS, by passing --break-system-packages.\n",
      "\u001b[1;36mhint\u001b[0m: See PEP 668 for the detailed specification.\n"
     ]
    }
   ],
   "source": [
    "!pip install nv-ingest-client==25.9.0 pymilvus[bulk_writer,model] minio tritonclient langchain_milvus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the python client "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each ingest job will include a set of stages. These stages define and configure the operations that will be performed during ingestion of the specified input files.\n",
    "\n",
    "- `extract` : Performs multimodal extractions from a document, including text, images, and tables.\n",
    "- `split` : Chunk the text into smaller chunks, useful for storing in a vector database for retrieval applications.\n",
    "- `dedup` : Identifies duplicate images in document that can be filtered to remove data redundancy.\n",
    "- `filter` : Filters out images that are likely not useful using some heuristics, including size and aspect ratio.\n",
    "- `embed` : Pass the text or table extractions through `\"nvidia/nv-embedqa-e5-v5` NIM to obtain its embeddings.\n",
    "- `store` : Save the extracted tables or images to MinIO, Milvus's storage system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nv_ingest_client'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnv_ingest_client\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mclient\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Ingestor\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Load a sample PDF to demonstrate NV-Ingest usage.\u001b[39;00m\n\u001b[32m      4\u001b[39m ingestor = ( \n\u001b[32m      5\u001b[39m     Ingestor(message_client_hostname=\u001b[33m\"\u001b[39m\u001b[33mhost.docker.internal\u001b[39m\u001b[33m\"\u001b[39m, message_client_port=\u001b[32m7670\u001b[39m)\n\u001b[32m      6\u001b[39m     .files(\u001b[33m\"\u001b[39m\u001b[33m./nv-ingest/data/multimodal_test.pdf\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;66;03m# can be a list of files, or contain wildcards i.e. /some/path/*.pdf\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     18\u001b[39m     ) \n\u001b[32m     19\u001b[39m )\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'nv_ingest_client'"
     ]
    }
   ],
   "source": [
    "from nv_ingest_client.client import Ingestor\n",
    "\n",
    "# Load a sample PDF to demonstrate NV-Ingest usage.\n",
    "ingestor = ( \n",
    "    Ingestor(message_client_hostname=\"host.docker.internal\", message_client_port=7670)\n",
    "    .files(\"./nv-ingest/data/multimodal_test.pdf\") # can be a list of files, or contain wildcards i.e. /some/path/*.pdf\n",
    "    .extract(\n",
    "        extract_text=True,\n",
    "        extract_tables=True,\n",
    "        extract_charts=True,\n",
    "        extract_images=True,\n",
    "    ).split(\n",
    "        tokenizer=\"meta-llama/Llama-3.2-1B\",\n",
    "        chunk_size=1024,\n",
    "        chunk_overlap=150,\n",
    "    ).embed( # whether to compute embeddings\n",
    "        text=True, tables=True\n",
    "    ) \n",
    ")\n",
    "\n",
    "# Result is a List[List[Dict]] - Each outer list Item [] is a file and each inner list Item [][] is an element in that file\n",
    "generated_metadata = ingestor.ingest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TestingDocument\\r\\nA sample document with headings and placeholder text\\r\\nIntroduction\\r\\nThis is a placeholder document that can be used for any purpose. It contains some \\r\\nheadings and some placeholder text to fill the space. The text is not important and contains \\r\\nno real value, but it is useful for testing. Below, we will have some simple tables and charts \\r\\nthat we can use to confirm Ingest is working as expected.\\r\\nTable 1\\r\\nThis table describes some animals, and some activities they might be doing in specific \\r\\nlocations.\\r\\nAnimal Activity Place\\r\\nGira@e Driving a car At the beach\\r\\nLion Putting on sunscreen At the park\\r\\nCat Jumping onto a laptop In a home o@ice\\r\\nDog Chasing a squirrel In the front yard\\r\\nChart 1\\r\\nThis chart shows some gadgets, and some very fictitious costs. Section One\\r\\nThis is the first section of the document. It has some more placeholder text to show how \\r\\nthe document looks like. The text is not meant to be meaningful or informative, but rather to \\r\\ndemonstrate the layout and formatting of the document.\\r\\n\u2022 This is the first bullet point\\r\\n\u2022 This is the second bullet point\\r\\n\u2022 This is the third bullet point\\r\\nSection Two\\r\\nThis is the second section of the document. It is more of the same as we\u2019ve seen in the rest \\r\\nof the document. The content is meaningless, but the intent is to create a very simple \\r\\nsmoke test to ensure extraction is working as intended. This will be used in CI as time goes \\r\\non to ensure that changes we make to the library do not negatively impact our accuracy.\\r\\nTable 2\\r\\nThis table shows some popular colors that cars might come in.\\r\\nCar Color1 Color2 Color3\\r\\nCoupe White Silver Flat Gray\\r\\nSedan White Metallic Gray Matte Gray\\r\\nMinivan Gray Beige Black\\r\\nTruck Dark Gray Titanium Gray Charcoal\\r\\nConvertible Light Gray Graphite Slate Gray\\r\\nPicture\\r\\nBelow, is a high-quality picture of some shapes. Chart 2\\r\\nThis chart shows some average frequency ranges for speaker drivers.\\r\\nConclusion\\r\\nThis is the conclusion of the document. It has some more placeholder text, but the most \\r\\nimportant thing is that this is the conclusion. As we end this document, we should have \\r\\nbeen able to extract 2 tables, 2 charts, and some text including 3 bullet points.\\nThis chart shows some gadgets, and some very fictitious costs Gadgets and their cost   Hammer - Powerdrill - Bluetooth speaker - Minifridge - Premium desk fan Dollars $- - $20.00 - $40.00 - $60.00 - $80.00 - $100.00 - $120.00 - $140.00 - $160.00 Cost    Chart 1\\n| Table 1 |\\n| This table describes some animals, and some activities they might be doing in specific |\\n| locations. |\\n| Animal | Activity | Place |\\n| Giraffe | Driving a car | At the beach |\\n| Lion | Putting on sunscreen | At the park |\\n| Cat | Jumping onto a laptop | In a home office |\\n| Dog | Chasing a squirrel | In the front yard |\\n\\nimage_caption:[]\\nimage_caption:[]\\nBelow,is a high-quality picture of some shapes          Picture\\n| Table 2 |\\n| This table shows some popular colors that cars might come in |\\n| Car | Color1 | Color2 | Color3 |\\n| Coupe | White | Silver | Flat Gray |\\n| Sedan | White | Metallic Gray | Matte Gray |\\n| Minivan | Gray | Beige | Black |\\n| Truck | Dark Gray | Titanium Gray | Charcoal |\\n| Convertible | Light Gray | Graphite | Slate Gray |\\n\\nimage_caption:[]\\nimage_caption:[]\\nThis chart shows some average frequency ranges for speaker drivers. Frequency Ranges ofSpeaker Drivers   Tweeter - Midrange - Midwoofer - Subwoofer Hertz (log scale) 1 - 10 - 100 - 1000 - 10000 - 100000 FrequencyRange Start (Hz) - Frequency Range End (Hz) - Midwoofer    Chart2\\nimage_caption:[]\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nv_ingest_client.util.process_json_files import ingest_json_results_to_blob\n",
    "\n",
    "# generated_metadata is the result of a batch of submitted files. We sample the first file metadata here for demonstration purposes.\n",
    "ingest_json_results_to_blob(generated_metadata[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the Outputs\n",
    "\n",
    "Let's explore elements of the NV-Ingest output. When data flows through an NV-Ingest pipeline, a number of extractions and transformations are performed. As the data is enriched, it is stored in rich metadata hierarchy. In the end, there will be a list of dictionaries, each of which represents a extracted type of information. The most common elements to extract from a dictionary in this hierarchy are the extracted content and the text representation of this content. The next few cells will demonstrate interacting with the metadata, pulling out these elements, and visualizing them. Note, when there is a -1 value present, this represents non-applicable positional resolution. Positive numbers represent valid positional data.\n",
    "\n",
    "For a more complete description of metadata elements, view the data dictionary.\n",
    "\n",
    "https://github.com/NVIDIA/nv-ingest/blob/main/docs/docs/extraction/content-metadata.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def redact_metadata_helper(metadata: dict) -> dict:\n",
    "    \"\"\"A simple helper function to redact `metadata[\"content\"]` and metadata[\"embedding\"]' to improve readability.\"\"\"\n",
    "    \n",
    "    text_metadata_redact = metadata.copy()\n",
    "    text_metadata_redact[\"metadata\"][\"content\"] = \"<---Redacted for readability--->\"\n",
    "    text_metadata_redact[\"metadata\"][\"embedding\"] = \"<---Redacted for readability--->\"\n",
    "    \n",
    "    return text_metadata_redact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Output - Text\n",
    "\n",
    "This cell depicts the full metadata hierarchy for a text extraction with redacted content to ease readability. Notice the following sections are populated with information:\n",
    "\n",
    "- `content` - The raw extracted content, text in this case - this section will always be populated with a successful job.\n",
    "- `content_metadata` - Describes the type of extraction and its position in the broader document - this section will always be populated with a successful job.\n",
    "- `source_metadata` - Describes the source document that is the basis of the ingest job.\n",
    "- `text_metadata` - Contain information about the text extraction, including detected language, among others - this section will only exist when `metadata['content_metadata']['document_type'] == 'text'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'document_type': 'text',\n",
       " 'metadata': {'content': '<---Redacted for readability--->',\n",
       "  'content_url': '',\n",
       "  'embedding': '<---Redacted for readability--->',\n",
       "  'source_metadata': {'source_name': './nv-ingest/data/multimodal_test.pdf',\n",
       "   'source_id': './nv-ingest/data/multimodal_test.pdf',\n",
       "   'source_location': '',\n",
       "   'source_type': 'PDF',\n",
       "   'collection_id': '',\n",
       "   'date_created': '2025-06-17T18:13:04.715946',\n",
       "   'last_modified': '2025-06-17T18:13:04.715805',\n",
       "   'summary': '',\n",
       "   'partition_id': -1,\n",
       "   'access_level': -1},\n",
       "  'content_metadata': {'type': 'text',\n",
       "   'description': 'Unstructured text from PDF document.',\n",
       "   'page_number': -1,\n",
       "   'hierarchy': {'page_count': 3,\n",
       "    'page': -1,\n",
       "    'block': -1,\n",
       "    'line': -1,\n",
       "    'span': -1,\n",
       "    'nearby_objects': {'text': {'content': [], 'bbox': [], 'type': []},\n",
       "     'images': {'content': [], 'bbox': [], 'type': []},\n",
       "     'structured': {'content': [], 'bbox': [], 'type': []}}},\n",
       "   'subtype': ''},\n",
       "  'audio_metadata': None,\n",
       "  'text_metadata': {'text_type': 'document',\n",
       "   'summary': '',\n",
       "   'keywords': '',\n",
       "   'language': 'en',\n",
       "   'text_location': [-1, -1, -1, -1],\n",
       "   'text_location_max_dimensions': [-1, -1]},\n",
       "  'image_metadata': None,\n",
       "  'table_metadata': None,\n",
       "  'chart_metadata': None,\n",
       "  'error_metadata': None,\n",
       "  'info_message_metadata': None,\n",
       "  'debug_metadata': None,\n",
       "  'raise_on_failure': False}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "redacted_text_metadata = redact_metadata_helper(generated_metadata[0][0])  # First file, first element of elements found within file [0][0]. There are 9 total\n",
    "redacted_text_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Output - Tables\n",
    "\n",
    "This cell depicts the full metadata hierarchy for a table extraction with redacted content to ease readability. Notice the following sections are populated with information:\n",
    "\n",
    "- `content` - The raw extracted content, a base64 encoded image of the extracted table in this case - this section will always be populated with a successful job.\n",
    "- `content_metadata` - Describes the type of extraction and its position in the broader document - this section will always be populated with a successful job.\n",
    "- `source_metadata` - Describes the source and storage path of an extracted table in an S3 compliant object store.\n",
    "- `table_metadata` - Contains the text representation of the table, positional data, and other useful elements - this section will only exist when `metadata['content_metadata']['document_type'] == 'structured'`.\n",
    "\n",
    "Note, `table_metadata` will store chart and table extractions. The are distringuished by `metadata['content_metadata']['subtype']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'document_type': 'structured',\n",
       " 'metadata': {'content': '<---Redacted for readability--->',\n",
       "  'content_url': '',\n",
       "  'embedding': '<---Redacted for readability--->',\n",
       "  'source_metadata': {'source_name': './nv-ingest/data/multimodal_test.pdf',\n",
       "   'source_id': './nv-ingest/data/multimodal_test.pdf',\n",
       "   'source_location': '',\n",
       "   'source_type': 'PDF',\n",
       "   'collection_id': '',\n",
       "   'date_created': '2025-06-17T18:13:04.715946',\n",
       "   'last_modified': '2025-06-17T18:13:04.715805',\n",
       "   'summary': '',\n",
       "   'partition_id': -1,\n",
       "   'access_level': -1},\n",
       "  'content_metadata': {'type': 'structured',\n",
       "   'description': 'Structured table extracted from PDF document.',\n",
       "   'page_number': 0,\n",
       "   'hierarchy': {'page_count': 3,\n",
       "    'page': 0,\n",
       "    'block': -1,\n",
       "    'line': -1,\n",
       "    'span': -1,\n",
       "    'nearby_objects': {'text': {'content': [], 'bbox': [], 'type': []},\n",
       "     'images': {'content': [], 'bbox': [], 'type': []},\n",
       "     'structured': {'content': [], 'bbox': [], 'type': []}}},\n",
       "   'subtype': 'table'},\n",
       "  'audio_metadata': None,\n",
       "  'text_metadata': None,\n",
       "  'image_metadata': None,\n",
       "  'table_metadata': {'caption': '',\n",
       "   'table_format': 'image',\n",
       "   'table_content': '| Table 1 |\\n| This table describes some animals, and some activities they might be doing in specific |\\n| locations. |\\n| Animal | Activity | Place |\\n| Giraffe | Driving a car | At the beach |\\n| Lion | Putting on sunscreen | At the park |\\n| Cat | Jumping onto a laptop | In a home office |\\n| Dog | Chasing a squirrel | In the front yard |\\n',\n",
       "   'table_content_format': 'pseudo_markdown',\n",
       "   'table_location': [92, 314, 697, 483],\n",
       "   'table_location_max_dimensions': [792, 1024],\n",
       "   'uploaded_image_uri': ''},\n",
       "  'chart_metadata': None,\n",
       "  'error_metadata': None,\n",
       "  'info_message_metadata': None,\n",
       "  'debug_metadata': None,\n",
       "  'raise_on_failure': False}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "redacted_table_metadata = redact_metadata_helper(generated_metadata[0][2])  # First file, third element within file [0][2]. There are 9 total\n",
    "redacted_table_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the CLI\n",
    "\n",
    "The CLI is another way to interact with nv-ingest. Notice that we have encoded tasks in the `--tasks` flag. This will store outputs in a `processed_docs` folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python-dotenv could not parse statement starting at line 1\n",
      "python-dotenv could not parse statement starting at line 2\n",
      "python-dotenv could not parse statement starting at line 3\n",
      "python-dotenv could not parse statement starting at line 4\n",
      "python-dotenv could not parse statement starting at line 5\n",
      "python-dotenv could not parse statement starting at line 6\n",
      "python-dotenv could not parse statement starting at line 7\n",
      "python-dotenv could not parse statement starting at line 8\n",
      "python-dotenv could not parse statement starting at line 9\n",
      "python-dotenv could not parse statement starting at line 10\n",
      "python-dotenv could not parse statement starting at line 11\n",
      "python-dotenv could not parse statement starting at line 12\n",
      "python-dotenv could not parse statement starting at line 13\n",
      "python-dotenv could not parse statement starting at line 14\n",
      "python-dotenv could not parse statement starting at line 15\n",
      "python-dotenv could not parse statement starting at line 16\n",
      "python-dotenv could not parse statement starting at line 17\n",
      "python-dotenv could not parse statement starting at line 18\n",
      "python-dotenv could not parse statement starting at line 19\n",
      "python-dotenv could not parse statement starting at line 20\n",
      "python-dotenv could not parse statement starting at line 21\n",
      "python-dotenv could not parse statement starting at line 22\n",
      "python-dotenv could not parse statement starting at line 23\n",
      "python-dotenv could not parse statement starting at line 24\n",
      "python-dotenv could not parse statement starting at line 25\n",
      "python-dotenv could not parse statement starting at line 26\n",
      "python-dotenv could not parse statement starting at line 27\n",
      "python-dotenv could not parse statement starting at line 28\n",
      "python-dotenv could not parse statement starting at line 29\n",
      "python-dotenv could not parse statement starting at line 30\n",
      "python-dotenv could not parse statement starting at line 31\n",
      "python-dotenv could not parse statement starting at line 32\n",
      "python-dotenv could not parse statement starting at line 33\n",
      "python-dotenv could not parse statement starting at line 34\n",
      "python-dotenv could not parse statement starting at line 35\n",
      "python-dotenv could not parse statement starting at line 36\n",
      "python-dotenv could not parse statement starting at line 37\n",
      "python-dotenv could not parse statement starting at line 38\n",
      "python-dotenv could not parse statement starting at line 39\n",
      "python-dotenv could not parse statement starting at line 40\n",
      "python-dotenv could not parse statement starting at line 41\n",
      "python-dotenv could not parse statement starting at line 42\n",
      "python-dotenv could not parse statement starting at line 43\n",
      "python-dotenv could not parse statement starting at line 44\n",
      "python-dotenv could not parse statement starting at line 45\n",
      "python-dotenv could not parse statement starting at line 46\n",
      "python-dotenv could not parse statement starting at line 47\n",
      "python-dotenv could not parse statement starting at line 48\n",
      "python-dotenv could not parse statement starting at line 49\n",
      "python-dotenv could not parse statement starting at line 50\n",
      "python-dotenv could not parse statement starting at line 51\n",
      "python-dotenv could not parse statement starting at line 52\n",
      "python-dotenv could not parse statement starting at line 53\n",
      "python-dotenv could not parse statement starting at line 54\n",
      "python-dotenv could not parse statement starting at line 55\n",
      "python-dotenv could not parse statement starting at line 56\n",
      "python-dotenv could not parse statement starting at line 57\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n",
      "INFO:nv_ingest_client.nv_ingest_cli:Processing 1 documents.\n",
      "INFO:nv_ingest_client.nv_ingest_cli:Output will be written to: ./processed_docs\n",
      "Processing files: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:02<00:00,  2.03s/file, pages_per_sec=1.47]\n",
      "INFO:nv_ingest_client.cli.util.processing:message_broker_task_source: Avg: 0.81 ms, Median: 0.81 ms, Total Time: 0.81 ms, Total % of Trace Computation: 0.02%\n",
      "INFO:nv_ingest_client.cli.util.processing:broker_source_network_in: Avg: 8.17 ms, Median: 8.17 ms, Total Time: 8.17 ms, Total % of Trace Computation: 0.23%\n",
      "INFO:nv_ingest_client.cli.util.processing:metadata_injector: Avg: 3.29 ms, Median: 3.29 ms, Total Time: 3.29 ms, Total % of Trace Computation: 0.09%\n",
      "INFO:nv_ingest_client.cli.util.processing:metadata_injector_channel_in: Avg: 5.47 ms, Median: 5.47 ms, Total Time: 5.47 ms, Total % of Trace Computation: 0.15%\n",
      "INFO:nv_ingest_client.cli.util.processing:pdf_extraction: Avg: 333.40 ms, Median: 163.39 ms, Total Time: 1667.01 ms, Total % of Trace Computation: 46.24%\n",
      "INFO:nv_ingest_client.cli.util.processing:pdf_extraction_channel_in: Avg: 5.16 ms, Median: 5.16 ms, Total Time: 5.16 ms, Total % of Trace Computation: 0.14%\n",
      "INFO:nv_ingest_client.cli.util.processing:audio_extractor: Avg: 0.02 ms, Median: 0.02 ms, Total Time: 0.02 ms, Total % of Trace Computation: 0.00%\n",
      "INFO:nv_ingest_client.cli.util.processing:audio_extractor_channel_in: Avg: 5.89 ms, Median: 5.89 ms, Total Time: 5.89 ms, Total % of Trace Computation: 0.16%\n",
      "INFO:nv_ingest_client.cli.util.processing:docx_extractor: Avg: 0.02 ms, Median: 0.02 ms, Total Time: 0.02 ms, Total % of Trace Computation: 0.00%\n",
      "INFO:nv_ingest_client.cli.util.processing:docx_extractor_channel_in: Avg: 6.23 ms, Median: 6.23 ms, Total Time: 6.23 ms, Total % of Trace Computation: 0.17%\n",
      "INFO:nv_ingest_client.cli.util.processing:pptx_extractor: Avg: 0.02 ms, Median: 0.02 ms, Total Time: 0.02 ms, Total % of Trace Computation: 0.00%\n",
      "INFO:nv_ingest_client.cli.util.processing:pptx_extractor_channel_in: Avg: 6.06 ms, Median: 6.06 ms, Total Time: 6.06 ms, Total % of Trace Computation: 0.17%\n",
      "INFO:nv_ingest_client.cli.util.processing:image_extraction: Avg: 0.02 ms, Median: 0.02 ms, Total Time: 0.02 ms, Total % of Trace Computation: 0.00%\n",
      "INFO:nv_ingest_client.cli.util.processing:image_extraction_channel_in: Avg: 6.25 ms, Median: 6.25 ms, Total Time: 6.25 ms, Total % of Trace Computation: 0.17%\n",
      "INFO:nv_ingest_client.cli.util.processing:html_extractor: Avg: 0.02 ms, Median: 0.02 ms, Total Time: 0.02 ms, Total % of Trace Computation: 0.00%\n",
      "INFO:nv_ingest_client.cli.util.processing:html_extractor_channel_in: Avg: 6.35 ms, Median: 6.35 ms, Total Time: 6.35 ms, Total % of Trace Computation: 0.18%\n",
      "INFO:nv_ingest_client.cli.util.processing:infographic_extraction: Avg: 0.02 ms, Median: 0.02 ms, Total Time: 0.02 ms, Total % of Trace Computation: 0.00%\n",
      "INFO:nv_ingest_client.cli.util.processing:infographic_extraction_channel_in: Avg: 6.38 ms, Median: 6.38 ms, Total Time: 6.38 ms, Total % of Trace Computation: 0.18%\n",
      "INFO:nv_ingest_client.cli.util.processing:table_extraction: Avg: 269.08 ms, Median: 269.08 ms, Total Time: 538.17 ms, Total % of Trace Computation: 14.93%\n",
      "INFO:nv_ingest_client.cli.util.processing:table_extraction_channel_in: Avg: 6.32 ms, Median: 6.32 ms, Total Time: 6.32 ms, Total % of Trace Computation: 0.18%\n",
      "INFO:nv_ingest_client.cli.util.processing:chart_extraction: Avg: 425.12 ms, Median: 478.19 ms, Total Time: 1275.35 ms, Total % of Trace Computation: 35.37%\n",
      "INFO:nv_ingest_client.cli.util.processing:chart_extraction_channel_in: Avg: 7.17 ms, Median: 7.17 ms, Total Time: 7.17 ms, Total % of Trace Computation: 0.20%\n",
      "INFO:nv_ingest_client.cli.util.processing:image_filter: Avg: 0.02 ms, Median: 0.02 ms, Total Time: 0.02 ms, Total % of Trace Computation: 0.00%\n",
      "INFO:nv_ingest_client.cli.util.processing:image_filter_channel_in: Avg: 7.82 ms, Median: 7.82 ms, Total Time: 7.82 ms, Total % of Trace Computation: 0.22%\n",
      "INFO:nv_ingest_client.cli.util.processing:image_deduplication: Avg: 0.02 ms, Median: 0.02 ms, Total Time: 0.02 ms, Total % of Trace Computation: 0.00%\n",
      "INFO:nv_ingest_client.cli.util.processing:image_deduplication_channel_in: Avg: 7.35 ms, Median: 7.35 ms, Total Time: 7.35 ms, Total % of Trace Computation: 0.20%\n",
      "INFO:nv_ingest_client.cli.util.processing:text_splitter: Avg: 0.02 ms, Median: 0.02 ms, Total Time: 0.02 ms, Total % of Trace Computation: 0.00%\n",
      "INFO:nv_ingest_client.cli.util.processing:text_splitter_channel_in: Avg: 7.34 ms, Median: 7.34 ms, Total Time: 7.34 ms, Total % of Trace Computation: 0.20%\n",
      "INFO:nv_ingest_client.cli.util.processing:text_embedding: Avg: 0.02 ms, Median: 0.02 ms, Total Time: 0.02 ms, Total % of Trace Computation: 0.00%\n",
      "INFO:nv_ingest_client.cli.util.processing:text_embedding_channel_in: Avg: 7.27 ms, Median: 7.27 ms, Total Time: 7.27 ms, Total % of Trace Computation: 0.20%\n",
      "INFO:nv_ingest_client.cli.util.processing:image_captioning: Avg: 0.02 ms, Median: 0.02 ms, Total Time: 0.02 ms, Total % of Trace Computation: 0.00%\n",
      "INFO:nv_ingest_client.cli.util.processing:image_captioning_channel_in: Avg: 7.07 ms, Median: 7.07 ms, Total Time: 7.07 ms, Total % of Trace Computation: 0.20%\n",
      "INFO:nv_ingest_client.cli.util.processing:image_storage: Avg: 0.02 ms, Median: 0.02 ms, Total Time: 0.02 ms, Total % of Trace Computation: 0.00%\n",
      "INFO:nv_ingest_client.cli.util.processing:image_storage_channel_in: Avg: 7.41 ms, Median: 7.41 ms, Total Time: 7.41 ms, Total % of Trace Computation: 0.21%\n",
      "INFO:nv_ingest_client.cli.util.processing:embedding_storage: Avg: 0.02 ms, Median: 0.02 ms, Total Time: 0.02 ms, Total % of Trace Computation: 0.00%\n",
      "INFO:nv_ingest_client.cli.util.processing:embedding_storage_channel_in: Avg: 6.84 ms, Median: 6.84 ms, Total Time: 6.84 ms, Total % of Trace Computation: 0.19%\n",
      "INFO:nv_ingest_client.cli.util.processing:No unresolved time detected. Trace times account for the entire elapsed duration.\n",
      "INFO:nv_ingest_client.cli.util.processing:Processed 1 files in 2.04 seconds.\n",
      "INFO:nv_ingest_client.cli.util.processing:Total pages processed: 3\n",
      "INFO:nv_ingest_client.cli.util.processing:Throughput (Pages/sec): 1.47\n",
      "INFO:nv_ingest_client.cli.util.processing:Throughput (Files/sec): 0.49\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "nv-ingest-cli \\\n",
    "  --doc nv-ingest/data/multimodal_test.pdf \\\n",
    "  --output_directory ./processed_docs \\\n",
    "  --task='extract:{\"document_type\": \"pdf\", \"extract_method\": \"pdfium\", \"extract_tables\": \"true\", \"extract_images\": \"true\", \"extract_charts\": \"true\"}' \\\n",
    "  --client_host=host.docker.internal \\\n",
    "  --client_port=7670"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}